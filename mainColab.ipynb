{"cells":[{"cell_type":"code","source":["from google.colab import runtime\n","#runtime.unassign()"],"metadata":{"id":"bDn4QUNSZBQf","executionInfo":{"status":"ok","timestamp":1744215167946,"user_tz":-60,"elapsed":47,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["###Install PyTorch Lightning package"],"metadata":{"id":"5AnCAg__AP1L"}},{"cell_type":"code","source":["!pip install lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVyyfG6Z13Mh","executionInfo":{"status":"ok","timestamp":1744215287267,"user_tz":-60,"elapsed":119316,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"outputId":"6ffa49e8-472c-4eb5-b869-8b505ddce35f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lightning\n","  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n","Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n","Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.3.2)\n","Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n","Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.6.0+cu124)\n","Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n","  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n","Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.13.1)\n","Collecting pytorch-lightning (from lightning)\n","  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n","Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-2.5.1 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1 torchmetrics-1.7.1\n"]}]},{"cell_type":"markdown","source":["###Link to Google Drive for dataset"],"metadata":{"id":"PMbE1Qa_Af8-"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSLIZiUA13ta","executionInfo":{"status":"ok","timestamp":1744215686273,"user_tz":-60,"elapsed":14928,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"outputId":"42cff470-c0ac-4bd6-9552-ee735a2ffa21"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["###Building the Vocabulary Document"],"metadata":{"id":"Z2mgxJQXAoP1"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"yV1utAGw0sf3","executionInfo":{"status":"ok","timestamp":1744215872745,"user_tz":-60,"elapsed":19,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"120ec067-b2c3-464d-ebb9-7857ae880ddc"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'A', 'NoRel', '\\\\cos', 'T', 'e', 'a', '\\\\in', '\\\\phi', 'v', '\\\\sigma', '\\\\prime', 'h', '\\\\lt', 'X', '\\\\sin', 'f', 'n', '\\\\{', 'l', '\\\\exists', 'c', '\\\\sqrt', 'y', 'o', '+', '\\\\ldots', 'L', '\\\\gamma', '/', 'B', '7', 'COMMA', 'k', 'Above', '\\\\gt', 'Below', 'G', 'F', '\\\\times', '\\\\div', 'r', '(', 'g', 'N', 'p', 'Sub', 'M', '4', '[', 'i', '2', 'R', '\\\\infty', '\\\\beta', '\\\\tan', 'S', '\\\\alpha', 's', '0', '\\\\mu', '\\\\sum', 'I', ']', '\\\\Delta', '\\\\pi', 'u', 'Sup', '\\\\pm', '\\\\geq', '|', 'Right', 'E', '3', ')', 'H', 'q', 'V', 'x', '5', '\\\\lambda', 'j', '8', '=', 'b', '\\\\lim', 'w', '\\\\rightarrow', '\\\\forall', '\\\\theta', '\\\\int', '9', 'P', '\\\\log', 't', 'd', 'm', '-', '\\\\}', '6', '!', 'Inside', 'z', 'C', '.', '\\\\leq', '\\\\neq', 'Y', '1'}\n"]}],"source":["files = ['/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt',\n","'/content/drive/MyDrive/CROHME2019/crohme2019_test.txt']\n","\n","vocabulary = set()\n","\n","for file in files:\n","    for line in open(file).readlines():\n","        #Check if all entries are formatted properly (Doc name + Target Output), and add each symbol as a token to the vocab set\n","        if len(line.strip().split('\\t')) == 2:\n","            vocabulary.update(line.strip().split('\\t')[1].split())\n","print(vocabulary)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Mc4dUFu40sf5","executionInfo":{"status":"ok","timestamp":1744215876397,"user_tz":-60,"elapsed":7,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#vocab_symbols only contains the symbols, not relations\n","vocab_symbols = [v for v in vocabulary if v not in ['Above', 'Below', 'Inside', 'NoRel', 'Right', 'Sub', 'Sup']]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"heVucRf60sf6","executionInfo":{"status":"ok","timestamp":1744215876422,"user_tz":-60,"elapsed":25,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Add these symbol tokens to the vocab doc, followed by the relation tokens\n","with open('crohme_vocab.txt', 'w') as f:\n","    f.writelines([c + '\\n' for c in sorted(vocab_symbols)])\n","    f.writelines([c + '\\n' for c in ['Above', 'Below', 'Inside', 'NoRel', 'Right', 'Sub', 'Sup']])\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NsF5-MFw0sf7","executionInfo":{"status":"ok","timestamp":1744215876430,"user_tz":-60,"elapsed":1,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["class Vocab(object):\n","    def __init__(self, vocab_file=None):\n","        self.word2index = {}\n","        self.index2word = {}\n","\n","        if vocab_file:\n","            self.load_vocab(vocab_file)\n","    #Add index values to each symbol token in the vocab file\n","    def load_vocab(self, vocab_file):\n","        # load vocab from file\n","        with open(vocab_file, 'r') as f:\n","            for i, line in enumerate(f):\n","                word = line.strip()\n","                self.word2index[word] = i\n","                self.index2word[i] = word\n","        # add blank word\n","        self.word2index['<blank>'] = len(self.word2index)\n","        self.index2word[self.word2index['<blank>']] = '<blank>'\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAkdJRRM0sf7","executionInfo":{"status":"ok","timestamp":1744215876478,"user_tz":-60,"elapsed":43,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"outputId":"fd78098e-69c1-4ab3-f952-bacbf99d8666"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: '!',\n"," 1: '(',\n"," 2: ')',\n"," 3: '+',\n"," 4: '-',\n"," 5: '.',\n"," 6: '/',\n"," 7: '0',\n"," 8: '1',\n"," 9: '2',\n"," 10: '3',\n"," 11: '4',\n"," 12: '5',\n"," 13: '6',\n"," 14: '7',\n"," 15: '8',\n"," 16: '9',\n"," 17: '=',\n"," 18: 'A',\n"," 19: 'B',\n"," 20: 'C',\n"," 21: 'COMMA',\n"," 22: 'E',\n"," 23: 'F',\n"," 24: 'G',\n"," 25: 'H',\n"," 26: 'I',\n"," 27: 'L',\n"," 28: 'M',\n"," 29: 'N',\n"," 30: 'P',\n"," 31: 'R',\n"," 32: 'S',\n"," 33: 'T',\n"," 34: 'V',\n"," 35: 'X',\n"," 36: 'Y',\n"," 37: '[',\n"," 38: '\\\\Delta',\n"," 39: '\\\\alpha',\n"," 40: '\\\\beta',\n"," 41: '\\\\cos',\n"," 42: '\\\\div',\n"," 43: '\\\\exists',\n"," 44: '\\\\forall',\n"," 45: '\\\\gamma',\n"," 46: '\\\\geq',\n"," 47: '\\\\gt',\n"," 48: '\\\\in',\n"," 49: '\\\\infty',\n"," 50: '\\\\int',\n"," 51: '\\\\lambda',\n"," 52: '\\\\ldots',\n"," 53: '\\\\leq',\n"," 54: '\\\\lim',\n"," 55: '\\\\log',\n"," 56: '\\\\lt',\n"," 57: '\\\\mu',\n"," 58: '\\\\neq',\n"," 59: '\\\\phi',\n"," 60: '\\\\pi',\n"," 61: '\\\\pm',\n"," 62: '\\\\prime',\n"," 63: '\\\\rightarrow',\n"," 64: '\\\\sigma',\n"," 65: '\\\\sin',\n"," 66: '\\\\sqrt',\n"," 67: '\\\\sum',\n"," 68: '\\\\tan',\n"," 69: '\\\\theta',\n"," 70: '\\\\times',\n"," 71: '\\\\{',\n"," 72: '\\\\}',\n"," 73: ']',\n"," 74: 'a',\n"," 75: 'b',\n"," 76: 'c',\n"," 77: 'd',\n"," 78: 'e',\n"," 79: 'f',\n"," 80: 'g',\n"," 81: 'h',\n"," 82: 'i',\n"," 83: 'j',\n"," 84: 'k',\n"," 85: 'l',\n"," 86: 'm',\n"," 87: 'n',\n"," 88: 'o',\n"," 89: 'p',\n"," 90: 'q',\n"," 91: 'r',\n"," 92: 's',\n"," 93: 't',\n"," 94: 'u',\n"," 95: 'v',\n"," 96: 'w',\n"," 97: 'x',\n"," 98: 'y',\n"," 99: 'z',\n"," 100: '|',\n"," 101: 'Above',\n"," 102: 'Below',\n"," 103: 'Inside',\n"," 104: 'NoRel',\n"," 105: 'Right',\n"," 106: 'Sub',\n"," 107: 'Sup',\n"," 108: '<blank>'}"]},"metadata":{},"execution_count":11}],"source":["#Check the vocab file\n","vocab = Vocab(vocab_file = 'crohme_vocab.txt')\n","vocab.index2word"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2fWaO8mE0sf7","executionInfo":{"status":"ok","timestamp":1744215876481,"user_tz":-60,"elapsed":2,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Test vocab against a random example\n","vocab = Vocab('crohme_vocab.txt')\n","input = '- Right \\\\sqrt Inside 2'.split()\n","output = [vocab.word2index[word] for word in input]\n","output\n","assert output == [4, 105, 66, 103, 9]"]},{"cell_type":"markdown","source":["###Classes to handle inkML files using XML namespaces (load filename, stroke data, segmentation and associated labels)"],"metadata":{"id":"HE0jl1RznjMF"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"5f3Z1XTy0sf8","executionInfo":{"status":"ok","timestamp":1744215876482,"user_tz":-60,"elapsed":2,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["import numpy as np\n","import xml.etree.ElementTree as ET\n","\n","#Class to reprsent a Segment compound of strokes (id) with an id and label\n","class Segment(object):\n","    __slots__ = ('id', 'label' ,'strId')\n","    def __init__(self, *args):\n","        if len(args) == 3:\n","            self.id = args[0]\n","            self.label = args[1]\n","            self.strId = args[2]\n","        else:\n","            self.id = \"none\"\n","            self.label = \"\"\n","            self.strId = set([])\n","\n","#Class to read an INKML file and extract strokes, segments and labels\n","class Inkml(object):\n","    __slots__ = ('fileName', 'strokes', 'strkOrder','segments','truth','UI')\n","\n","    NS = {'ns': 'http://www.w3.org/2003/InkML', 'xml': 'http://www.w3.org/XML/1998/namespace'}\n","\n","    def __init__(self,*args):\n","        self.fileName = None\n","        self.strokes = {}\n","        self.strkOrder = []\n","        self.segments = {}\n","        self.truth = \"\"\n","        self.UI = \"\"\n","        if len(args) == 1:\n","            self.fileName = args[0]\n","            self.loadFromFile()\n","\n","    #Build the right tag or element name with namespace\n","    def fixNS(self,ns,att):\n","        return '{'+Inkml.NS[ns]+'}'+att\n","\n","    #Load the ink from an InkML file, handling both standard and namespaced formats\n","    def loadFromFile(self):\n","            tree = ET.parse(self.fileName)\n","            root = tree.getroot()\n","\n","    # Extract annotations (ground truth expressions)\n","            for info in root.findall('.//annotation'):\n","                if 'type' in info.attrib:\n","                    if info.attrib['type'] == 'truth':\n","                        self.truth = info.text.strip()\n","                    if info.attrib['type'] == 'UI':\n","                        self.UI = info.text.strip()\n","\n","    # Handle both namespaced and non-namespaced formats\n","            for strk in root.findall('.//{http://www.w3.org/2003/InkML}trace'):\n","                trace_id = strk.attrib.get('id', strk.attrib.get('{http://www.w3.org/XML/1998/namespace}id', str(len(self.strokes))))\n","\n","    # Ensure stroke data is valid\n","                if strk.text:\n","                    self.strokes[trace_id] = strk.text.strip()\n","                    self.strkOrder.append(trace_id)\n","\n","\n","    def getTraces(self, height = 256):\n","        #Net ink traces from the inkml file (useful for visualizing)\n","        traces_array = [np.array([p.strip().split()\n","            for p in self.strokes[id].split(',')], dtype='float')\n","              for id in self.strkOrder ]\n","        #Normalize the dimensions of the representation to fit into a box of fixed dimensions ()\n","        ratio = height / ((np.concatenate(traces_array, 0).max(0) - np.concatenate(traces_array, 0).min(0))[1] + 1e-6)\n","        return [(trace * ratio).astype(int).tolist() for trace in traces_array]"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"id":"lCbMUxML0sf8","executionInfo":{"status":"error","timestamp":1744215876533,"user_tz":-60,"elapsed":53,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"outputId":"49ec133d-113d-4803-a45f-9e8c3ce2a3c7"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/sample1.inkml'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-2c8672105413>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/sample1.inkml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInkml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#visualize_file(ink)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-440e36bf04ac>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#Build the right tag or element name with namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-440e36bf04ac>\u001b[0m in \u001b[0;36mloadFromFile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#Load the ink from an InkML file, handling both standard and namespaced formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \"\"\"\n\u001b[1;32m   1218\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample1.inkml'"]}],"source":["import matplotlib.pyplot as plt\n","\n","#Function to visualize inkML files\n","def visualize_file(ink_obj: Inkml):\n","    ink = ink_obj\n","\n","    plt.figure(figsize=(16, 6))\n","    plt.axis(\"off\")\n","    for trace in ink.getTraces():\n","        trace_arr = np.array(trace)\n","        plt.plot(trace_arr[:, 0], -trace_arr[:, 1])  #Invert y coordinate to visualize, as origin is at top left of inkML file\n","\n","\n","path = '/content/sample1.inkml'\n","ink = Inkml(path)\n","#visualize_file(ink)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVC0Chgx0sf9","executionInfo":{"status":"aborted","timestamp":1744215876572,"user_tz":-60,"elapsed":41,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Ink object from an InkML file\n","ink = Inkml('/content/drive/MyDrive/CROHME2019/crohme2019/crohme2019/valid/18_em_0.inkml')\n","\n","#Get dimesnion of traces from the ink object\n","[np.array(trace).shape for trace in ink.getTraces()]"]},{"cell_type":"markdown","source":["###Building the Dataset Class\n","- Below implementation is for testing only, actual implementation is CROHME(Dataset)"],"metadata":{"id":"ZQmuKXB_q7-g"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"uT8gdTmg0sf-","executionInfo":{"status":"ok","timestamp":1744215882316,"user_tz":-60,"elapsed":24,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Testing Dataset class for structure\n","from torch.utils.data import Dataset\n","import os\n","import xml.etree.ElementTree as ET\n","\n","class InkmlDataset(Dataset):\n","    def __init__(self, annotation, root_directory, vocab):\n","        self.annotation = annotation\n","        self.root_directory = root_directory\n","        self.vocab = vocab\n","\n","        # Load annotations\n","        self.ink_paths = []\n","        self.labels = []\n","\n","        # Read annotation file and populate self.ink_paths and self.labels\n","        with open(self.annotation, 'r') as f:\n","            for line in f:\n","                parts = line.strip().split(',')\n","                if len(parts) == 2:\n","                    ink_file, label = parts\n","                    self.ink_paths.append(os.path.join(self.root_directory, ink_file))\n","                    self.labels.append(label)\n","\n","    def __len__(self):\n","        # Return the number of samples in the dataset\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # Return the idx-th sample in the dataset\n","        if idx >= len(self.labels):\n","            raise IndexError(\"Index out of range\")\n","\n","        inkmlfile = self.ink_paths[idx]\n","        label = self.labels[idx]\n","\n","        # Read inkml file to extract traces\n","        tree = ET.parse(inkmlfile)\n","        root = tree.getroot()\n","        traces = []\n","        for trace in root.findall('trace'):\n","            points = []\n","            for point in trace.text.strip().split(','):\n","                x, y = map(float, point.split(' '))\n","                points.append((x, y))\n","            traces.append(points)\n","\n","        # Feature extraction\n","        feature = self.extract_features(traces)\n","\n","        # Convert label tokens into vocab indexes\n","        label_indexes = [self.vocab[token] for token in label.split()]\n","\n","        input_len = len(feature)\n","        label_len = len(label_indexes)\n","\n","        return feature, label_indexes, input_len, label_len"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"GQx1PSUf0sf_","executionInfo":{"status":"ok","timestamp":1744215882364,"user_tz":-60,"elapsed":47,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Function to remove any duplicate coordinates in the trace\n","def remove_duplicate(trace):\n","    if not trace:\n","        return []\n","\n","    new_trace = [trace[0]]  # Start with the first point\n","    for point in trace[1:]:\n","        if point != new_trace[-1]:  # Add to new_trace if not duplicate of the last point\n","            new_trace.append(point)\n","\n","    return new_trace"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"AAObiCAm0sf_","executionInfo":{"status":"ok","timestamp":1744215882365,"user_tz":-60,"elapsed":3,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Testing the remove_duplicate() function\n","ink = Inkml('/content/drive/MyDrive/CROHME2019/crohme2019/crohme2019/valid/18_em_0.inkml')\n","traces = ink.getTraces()\n","traces = [remove_duplicate(trace) for trace in traces]\n","\n","assert list(map(len,traces)) == [82, 16, 21, 78, 82, 15, 18, 18, 28, 58, 15, 19, 56, 70, 18, 21]"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"2QnXjhTt0sgC","executionInfo":{"status":"ok","timestamp":1744215882366,"user_tz":-60,"elapsed":3,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Function to calculate the normalised stroke gradients\n","import numpy as np\n","\n","def feature_extraction(traces):\n","    features = []\n","    last_point = None  #Variable to keep track of the last point in the current stroke\n","\n","    for stroke in traces:\n","        if len(stroke) == 0:\n","            continue  #Skip empty strokes\n","\n","        #Handle the pen-up event (last point of the previous stroke to the first point of the current stroke)\n","        if last_point is not None:\n","            x1, y1, *_ = last_point\n","            x2, y2, *_ = stroke[0]\n","            dx = x2 - x1\n","            dy = y2 - y1\n","            distance = (dx**2 + dy**2)**0.5\n","            pen_up = 1  #Pen-up event\n","\n","            #Only append if distance is non-zero\n","            if distance > 0:\n","                features.append([dx / distance, dy / distance, distance, pen_up])\n","\n","        #Process points within the current stroke\n","        for i in range(1, len(stroke)):\n","            x1, y1, *_ = stroke[i - 1]\n","            x2, y2, *_ = stroke[i]\n","            dx = x2 - x1\n","            dy = y2 - y1\n","            distance = (dx**2 + dy**2)**0.5\n","            pen_up = 0  #Pen-down event\n","\n","            #Only append if distance is non-zero (ie. it is a valid stroke or a jump to next character)\n","            if distance > 0:\n","                features.append([dx / distance, dy / distance, distance, pen_up])\n","\n","        #Update last_point to the last point of the current stroke\n","        last_point = stroke[-1]\n","\n","    return np.array(features)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"lqsjivya0sgC","executionInfo":{"status":"ok","timestamp":1744215882372,"user_tz":-60,"elapsed":8,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Test feature_extraction function\n","ink = Inkml('/content/drive/MyDrive/CROHME2019/crohme2019/crohme2019/valid/18_em_0.inkml')\n","traces = ink.getTraces()\n","traces = [remove_duplicate(trace) for trace in traces]\n","feature = feature_extraction(traces)\n","\n","import numpy.testing as npt\n","assert feature.shape == (614, 4)\n","npt.assert_array_equal(np.where(feature[:,3] == 1)[0], np.array([ 81,  97, 118, 196, 278, 293, 311, 329, 357, 415, 430, 449, 505,\n","       575, 593]))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"_eoUWfoY0sgC","executionInfo":{"status":"ok","timestamp":1744215882380,"user_tz":-60,"elapsed":2,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","import os\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","import math\n","import torch\n","\n","#Dataset class for loading the dataset files for the model (train, validation and test) and pre-processing the files\n","class CROHME(Dataset):\n","    def __init__(self, annotation, root_directory, vocab):\n","        self.annotation = annotation\n","        self.root_directory = root_directory\n","        self.vocab = vocab\n","        self.ink_paths = []\n","        self.labels = []\n","\n","        with open(self.annotation, 'r') as f:\n","            for line in f:\n","                parts = line.strip().split('\\t')\n","                if len(parts) == 2: #Make sure the file is of the format [Filename, labels]\n","                    ink_file, label = parts\n","                    full_path = os.path.join(self.root_directory, ink_file)\n","                    self.ink_paths.append(full_path)\n","                    self.labels.append(label)\n","\n","        print(f\"Total samples loaded: {len(self.ink_paths)}\")\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        inkmlfile = self.ink_paths[idx]\n","        label = self.labels[idx]\n","\n","        ink = Inkml(inkmlfile)\n","\n","        #Get traces from the ink object\n","        traces = ink.getTraces()\n","\n","        processed_traces = [self.remove_duplicate(trace) for trace in traces]\n","        feature = feature_extraction(processed_traces)\n","\n","        if not feature.size: #Check if any features are extracted, if not, return empty tensors and length = 0\n","            print(f\"No features extracted from {inkmlfile}.\")\n","            return torch.tensor([]), torch.tensor([]), 0, 0\n","\n","        label_indexes = [self.vocab.word2index.get(token, self.vocab.word2index.get('<unk>', 0)) for token in label.split(' ')]\n","\n","        feature_tensor = torch.tensor(feature, dtype=torch.float)\n","        label_tensor = torch.tensor(label_indexes, dtype=torch.long)\n","\n","        return feature_tensor, label_tensor, len(feature), len(label_indexes)\n","\n","    def remove_duplicate(self, trace): #Get rid of duplicate traces\n","        new_trace = [trace[0]] if trace else []\n","        for point in trace[1:]:\n","            if point != new_trace[-1]:\n","                new_trace.append(point)\n","        return new_trace"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87JjKLZc0sgD","executionInfo":{"status":"ok","timestamp":1744215882405,"user_tz":-60,"elapsed":21,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"outputId":"ddba6764-a14e-4d03-b6d1-b88c9cc19478"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total samples loaded: 986\n"]}],"source":["#Test dataset class against datatypes and label values\n","dataset = CROHME(annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt', root_directory='/content/drive/MyDrive/CROHME2019/crohme2019', vocab=Vocab('crohme_vocab.txt'))\n","feature, label, input_len, label_len = dataset.__getitem__(0)\n","\n","import numpy.testing as npt\n","\n","assert type(feature) == torch.Tensor\n","assert type(label) == torch.Tensor\n","assert feature.shape == (231, 4)\n","npt.assert_array_equal(label, np.array([59, 105, 1, 105, 59, 105, 1, 105, 87, 105, 2, 105, 2]))\n","assert input_len == 231\n","assert label_len == 13"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Ocadp-pV0sgD","executionInfo":{"status":"ok","timestamp":1744215882413,"user_tz":-60,"elapsed":1,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["import torch\n","\n","#Function to batch-process samples for feeding to the model\n","def collate_function(batch):\n","    # Sort the batch in the descending order of input lengths\n","    batch.sort(key=lambda x: x[2], reverse=True)\n","\n","    # Separate the batch into its components\n","    features, labels, input_lens, label_lens = zip(*batch)\n","\n","    # Pad the sequences with 0 values, using clone().detach() to avoid the warning\n","    features_padded = torch.nn.utils.rnn.pad_sequence([f.clone().detach() for f in features], batch_first=True, padding_value=0)\n","    labels_padded = torch.nn.utils.rnn.pad_sequence([l.clone().detach() for l in labels], batch_first=True, padding_value=-1)  # Assuming -1 is an ignore_index\n","\n","    # Convert lengths to tensor\n","    input_lens = torch.tensor(input_lens)\n","    label_lens = torch.tensor(label_lens)\n","\n","    return features_padded, labels_padded, input_lens, label_lens"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"shalGEp_0sgD","executionInfo":{"status":"ok","timestamp":1744215882461,"user_tz":-60,"elapsed":6,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Test collate function\n","features, labels, input_lens, label_lens = collate_function([dataset[0], dataset[1]])\n","\n","import numpy.testing as npt\n","\n","assert type(input_lens) == torch.Tensor\n","assert type(label_lens) == torch.Tensor\n","\n","assert features.shape == (2, 231, 4)\n","assert labels.shape == (2, 13)\n","npt.assert_array_equal(input_lens.numpy(), np.array([231, 102]))\n","npt.assert_array_equal(label_lens, np.array([13, 5]))"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"IMq0tjNU0sgD","executionInfo":{"status":"ok","timestamp":1744215882563,"user_tz":-60,"elapsed":101,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["#Test collate function with data loader\n","from torch.utils.data import DataLoader\n","data_loader = DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_function)\n","\n","features, labels, input_lens, label_lens = next(iter(data_loader))\n","assert features.shape == (2, 231, 4)\n","assert labels.shape == (2, 13)\n","npt.assert_array_equal(input_lens.numpy(), np.array([231, 102]))\n","npt.assert_array_equal(label_lens, np.array([13, 5]))"]},{"cell_type":"markdown","source":["###Data Module\n","- Manages dataset (train, validate and test) for training and testing the model\n","- Follows PyTorch Lightning's Datamodule structure"],"metadata":{"id":"PEE6XX59olcP"}},{"cell_type":"code","execution_count":25,"metadata":{"id":"XgQwoHtu0sgD","executionInfo":{"status":"ok","timestamp":1744215882603,"user_tz":-60,"elapsed":41,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["import pytorch_lightning as pl\n","'''class CROHMEDM(pl.LightningDataModule):\n","    def __init__(self, root_directory, train_annotation, validation_annotation, test_annotation, vocab_file, batch_size, num_workers):\n","        super().__init__()\n","        self.root_directory = root_directory\n","        self.batch_size = batch_size\n","        self.train_annotation = train_annotation\n","        self.validation_annotation = validation_annotation\n","        self.test_annotation = test_annotation\n","        self.vocab = Vocab(vocab_file)\n","        self.num_workers = num_workers\n","\n","    def setup(self, stage: str):\n","        self.train_dataset = CROHME(self.train_annotation, self.root_directory, self.vocab)\n","        self.validation_dataset = CROHME(self.validation_annotation, self.root_directory, self.vocab)\n","        self.test_dataset = CROHME(self.test_annotation, self.root_directory, self.vocab)\n","\n","    def train_dataloader(self): #Shuffle set to true to avoid overfitting on training set\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=collate_function)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.validation_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=collate_function)\n","\n","    def test_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=collate_function)'''\n","\n","\n","class CROHMEDM(pl.LightningDataModule):\n","    def __init__(self, root_directory, train_annotation, validation_annotation, test_annotation, vocab_file, batch_size, num_workers):\n","        super().__init__()\n","        self.root_directory = root_directory\n","        self.batch_size = batch_size\n","        self.train_annotation = train_annotation\n","        self.validation_annotation = validation_annotation\n","        self.test_annotation = test_annotation\n","        self.vocab = Vocab(vocab_file)\n","        self.num_workers = num_workers\n","\n","        # Set dataset attributes to None initially\n","        self.train_dataset = None\n","        self.validation_dataset = None\n","        self.test_dataset = None\n","\n","    def setup(self, stage: str = None):\n","        \"\"\"Initialize datasets properly before calling dataloaders.\"\"\"\n","\n","        self.train_dataset = CROHME(self.train_annotation, self.root_directory, self.vocab)\n","        self.validation_dataset = CROHME(self.validation_annotation, self.root_directory, self.vocab)\n","        self.test_dataset = CROHME(self.test_annotation, self.root_directory, self.vocab)\n","\n","        print(\"Datasets initialized successfully!\")\n","        print(f\"Train Dataset Size: {len(self.train_dataset)}\")\n","        print(f\"Validation Dataset Size: {len(self.validation_dataset)}\")\n","        print(f\"Test Dataset Size: {len(self.test_dataset)}\")\n","\n","    def train_dataloader(self):\n","        if self.train_dataset is None:\n","            raise ValueError(\"Train dataset is not initialized! Call `setup()` first.\")\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=collate_function)\n","\n","    def val_dataloader(self):\n","        if self.validation_dataset is None:\n","            raise ValueError(\"Validation dataset is not initialized! Call `setup()` first.\")\n","        return DataLoader(self.validation_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=collate_function)\n","\n","    def test_dataloader(self):\n","        if self.test_dataset is None:\n","            raise ValueError(\"Test dataset is not initialized! Call `setup()` first.\")\n","        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=collate_function)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"e7JcgFcA0sgD","executionInfo":{"status":"ok","timestamp":1744215882603,"user_tz":-60,"elapsed":2,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["import torch.nn as nn\n","\n","#Initialising the LSTM Model\n","class LSTM_Model(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(LSTM_Model, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=True, batch_first=True)\n","        self.fc = nn.Linear(hidden_size * 2, num_classes)  # Multiply by 2 for bidirectional\n","        self.vocab = Vocab('crohme_vocab.txt')\n","\n","    def forward(self, x):\n","        # Forward propagate LSTM\n","        out, _ = self.lstm(x)  #Out: tensor of shape (batch_size, seq_length, hidden_size*2)\n","\n","        # Apply the fully connected layer to each time step\n","        out = self.fc(out)  #New out: tensor of shape (batch_size, seq_length, num_classes)\n","\n","        return out"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHkb0nt60sgE","executionInfo":{"status":"ok","timestamp":1744215883056,"user_tz":-60,"elapsed":454,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"outputId":"16e052eb-a46c-4d52-d019-176cc865c6a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model test passed!\n"]}],"source":["#Test the LSTM model\n","model = LSTM_Model(4, 128, 3, 109)\n","assert model.forward(torch.rand((10, 100, 4))).shape == (10, 100, 109)\n","print(\"Model test passed!\")"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"bIUt_PSO0sgE","executionInfo":{"status":"ok","timestamp":1744215883086,"user_tz":-60,"elapsed":14,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"colab":{"base_uri":"https://localhost:8080/","height":146},"outputId":"e57d78f6-6fea-4b53-88c4-c604dce770d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'from torchmetrics.functional import accuracy\\n\\nclass ClassificationTask(pl.LightningModule):\\n    def __init__(self, model):\\n        super().__init__()\\n        self.model = model\\n\\n    def training_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self.model(x)\\n        loss = F.cross_entropy(y_hat, y)\\n        return loss\\n\\n    def validation_step(self, batch, batch_idx):\\n        loss, acc = self._shared_eval_step(batch, batch_idx)\\n        metrics = {\"val_acc\": acc, \"val_loss\": loss}\\n        self.log_dict(metrics)\\n        return metrics\\n\\n    def test_step(self, batch, batch_idx):\\n        loss, acc = self._shared_eval_step(batch, batch_idx)\\n        metrics = {\"test_acc\": acc, \"test_loss\": loss}\\n        self.log_dict(metrics)\\n        return metrics\\n\\n    def _shared_eval_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self.model(x)\\n        loss = F.cross_entropy(y_hat, y)\\n        acc = accuracy(y_hat, y)\\n        return loss, acc\\n\\n    def configure_optimizers(self):\\n        return torch.optim.Adam(self.model.parameters(), lr=0.02)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}],"source":["#Example implementation of a Classifier Model\n","'''from torchmetrics.functional import accuracy\n","\n","class ClassificationTask(pl.LightningModule):\n","    def __init__(self, model):\n","        super().__init__()\n","        self.model = model\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self.model(x)\n","        loss = F.cross_entropy(y_hat, y)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, acc = self._shared_eval_step(batch, batch_idx)\n","        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n","        self.log_dict(metrics)\n","        return metrics\n","\n","    def test_step(self, batch, batch_idx):\n","        loss, acc = self._shared_eval_step(batch, batch_idx)\n","        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n","        self.log_dict(metrics)\n","        return metrics\n","\n","    def _shared_eval_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self.model(x)\n","        loss = F.cross_entropy(y_hat, y)\n","        acc = accuracy(y_hat, y)\n","        return loss, acc\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.model.parameters(), lr=0.02)'''"]},{"cell_type":"markdown","source":["###Model Training\n"],"metadata":{"id":"8StRgrij0ij7"}},{"cell_type":"code","execution_count":29,"metadata":{"id":"qC9wt-sx0sgE","executionInfo":{"status":"ok","timestamp":1744215883121,"user_tz":-60,"elapsed":24,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"outputs":[],"source":["import pytorch_lightning as pl\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MathClassificationModel(pl.LightningModule):\n","    def __init__(self, lr=0.001, input_size=4, output_size=109, hidden_size=128, num_layers=3, decoder=None):\n","        super().__init__()\n","        self.model = LSTM_Model(input_size, hidden_size, num_layers, output_size)\n","        self.criterion = nn.CTCLoss(blank=output_size - 1)\n","        self.lr = lr\n","        self.decoder = decoder\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y, input_lengths, target_lengths = batch\n","        y_hat = self.model(x)\n","        y_hat = y_hat.permute(1, 0, 2)\n","        loss = self.criterion(y_hat.log_softmax(2), y, input_lengths, target_lengths)\n","        self.log('Train_Loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n","        return {'Train_Loss': loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y, input_lengths, target_lengths = batch\n","        y_hat = self.model(x)\n","        y_hat = y_hat.permute(1, 0, 2)\n","        loss = self.criterion(y_hat.log_softmax(2), y, input_lengths, target_lengths)\n","        self.log('Val_Loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n","        return {'Val_Loss': loss}\n","\n","    def test_step(self, batch, batch_idx):\n","        x, y, input_lengths, target_lengths = batch\n","        y_hat = self.model(x)\n","        y_hat = y_hat.permute(1, 0, 2)\n","        loss = self.criterion(y_hat.log_softmax(2), y, input_lengths, target_lengths)\n","        self.log('Test_Loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n","        return {'Test_Loss': loss}\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":881,"referenced_widgets":["1a5c7496a2984e93a17efd9c21717a31","42b24886ac104eae900cc5d76673375b","bec22cc6bbd94b82b4e20a7aa8841198","178e86da71364ff5a929b458ff726316","7be63f10809c452d92d5f15b00eebca0","dc07cb5618dc429f87787ce26012d516","1bbcb121928a4ea6890317d6340cbe72","bc5027f857964b7bb9c57ef93efa05a7","f3fe10fe70b046b59cc758c3b1c06ec6","10978f41d238448e91c0fa9923e31634","099be7b0cff242a2aeb909ba6dcebace","6cff7f9cdb6f443f972a233c105b2644","bce5f2f70bc4420a9bd7ee8580ae9903","c8198c97fcde40f49aa5323b066a1110","72469622f83245ffaab39dc9bbf3f610","88d8832253544669974d249384cd1575","7ab32367ce6d4740935a633ced4d570c","0db9e2772a72456fbbc31a5ebb0d167d","feef21d37e5e4e15876093025dbd60e2","08045f89ec0f48dc82202bc3c4da6cc4","170bbd4542084dc3968204a0ff7e3eda","3aaf0a8980c943b0a4f10dc538c9d9c7"]},"id":"kLukbSIS0sgE","executionInfo":{"status":"error","timestamp":1744215899150,"user_tz":-60,"elapsed":16022,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}},"outputId":"ba5034bf-ab97-4bec-db28-a379491228a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]},{"output_type":"stream","name":"stdout","text":["Total samples loaded: 8900\n","Total samples loaded: 986\n","Total samples loaded: 1198\n","Datasets initialized successfully!\n","Train Dataset Size: 8900\n","Validation Dataset Size: 986\n","Test Dataset Size: 1198\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name      | Type       | Params | Mode \n","-------------------------------------------------\n","0 | model     | LSTM_Model | 955 K  | train\n","1 | criterion | CTCLoss    | 0      | train\n","-------------------------------------------------\n","955 K     Trainable params\n","0         Non-trainable params\n","955 K     Total params\n","3.823     Total estimated model params size (MB)\n","4         Modules in train mode\n","0         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a5c7496a2984e93a17efd9c21717a31"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _xla_gc_callback at 0x79770f6cb100>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n","    def _xla_gc_callback(*args):\n","    \n","KeyboardInterrupt: \n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cff7f9cdb6f443f972a233c105b2644"}},"metadata":{}},{"output_type":"error","ename":"MisconfigurationException","evalue":"In automatic_optimization, when `training_step` returns a dict, the 'loss' key needs to be present","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-70e30f70e992>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \"\"\"\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model_and_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     def _clip_gradients(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m             )\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_result_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_training_step_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_step_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate_grad_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mfrom_training_step_output\u001b[0;34m(cls, training_step_output, normalize)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mclosure_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 raise MisconfigurationException(\n\u001b[0m\u001b[1;32m     69\u001b[0m                     \u001b[0;34m\"In automatic_optimization, when `training_step` returns a dict, the 'loss' key needs to be present\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 )\n","\u001b[0;31mMisconfigurationException\u001b[0m: In automatic_optimization, when `training_step` returns a dict, the 'loss' key needs to be present"]}],"source":["from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from pytorch_lightning import Trainer\n","\n","#Define the trainer\n","train = Trainer(\n","    callbacks=[\n","        LearningRateMonitor(logging_interval='step'),\n","        ModelCheckpoint(filename='{epoch}-{val_loss:.4f}', save_top_k=5, monitor='val_loss', mode='min'),\n","    ],\n","    logger=TensorBoardLogger('lightning_logs'),\n","    check_val_every_n_epoch=1,\n","    fast_dev_run=False,\n","    default_root_dir='checkpoint',\n","    deterministic=False,\n","    max_epochs=10,\n","    log_every_n_steps=10,\n","    devices=1,\n",")\n","\n","#Initialize the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MathClassificationModel().to(device)\n","#model = MathClassificationModel.load_from_checkpoint(\n","    #'')\n","\n","#Initialize the data module\n","dm = CROHMEDM(\n","    root_directory='/content/drive/MyDrive/CROHME2019/crohme2019',\n","    train_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_train.txt',\n","    validation_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt',\n","    test_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_test.txt',\n","    vocab_file='crohme_vocab.txt',\n","    batch_size=8,\n","    num_workers=4\n",")\n","\n","#Train the model\n","train.fit(model, datamodule = dm)"]},{"cell_type":"code","source":["from pytorch_lightning import Trainer\n","\n","#Run test on validation dataset with best val_loss model\n","train = Trainer(\n","    devices = 1,\n",")\n","\n","# Load the model from a checkpoint\n","model = MathClassificationModel.load_from_checkpoint(\"/content/drive/MyDrive/FYP/epoch=9-val_loss=0.6140.ckpt\")\n","\n","# Initialize the data module\n","dm = CROHMEDM(\n","    root_directory='/content/drive/MyDrive/CROHME2019/crohme2019',\n","    train_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_train.txt',\n","    validation_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt',\n","    test_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_test.txt',\n","    vocab_file='crohme_vocab.txt',\n","    batch_size=8,\n","    num_workers=4\n",")\n","\n","#Test the model\n","train.test(model, datamodule=dm)"],"metadata":{"id":"wpH5QFYl7DiG","executionInfo":{"status":"aborted","timestamp":1744215899154,"user_tz":-60,"elapsed":1,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import List\n","import torch\n","\n","#Decoder class using Greedy Decoder\n","class GreedyDecoder(torch.nn.Module):\n","    def __init__(self, vocab):\n","        super().__init__()\n","        self.vocab = vocab\n","        self.blank = vocab.word2index['<blank>']\n","\n","    #Given a sequence emission (logits tensor) over labels, get the best decoding\n","    def forward(self, emission: torch.Tensor) -> List[str]:\n","\n","        indices = torch.argmax(emission, dim=-1) #Get most probable indices for each time step\n","        indices = [indices[0].item()] + [indices[i].item() for i in range(1, indices.shape[0]) if indices[i] != indices[i-1]] #Remove duplicates\n","        indices = [idx for idx in indices if idx != self.blank] #Remove blank values\n","        output_seq_list = [self.vocab.index2word[idx] for idx in indices] #Convert indices to decoded symbols\n","\n","        return output_seq_list"],"metadata":{"id":"Vd14nCsL85V9","executionInfo":{"status":"ok","timestamp":1744215907663,"user_tz":-60,"elapsed":7,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["#Load the best val_loss model to test greedy decoder\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MathClassificationModel.load_from_checkpoint('/content/drive/MyDrive/FYP/epoch=9-val_loss=0.6140.ckpt')\n","model = model.to(device)\n","model.eval()\n","\n","dataset = CROHME(annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt', root_directory='/content/drive/MyDrive/CROHME2019/crohme2019', vocab=Vocab('crohme_vocab.txt'))\n","feature, label, input_len, label_len = dataset.__getitem__(0)\n","feature = feature.to(device)  # Move feature to the same device as the model\n","\n","greedy_decoder = GreedyDecoder(vocab)\n","\n","# Run model forward with feature --> output\n","output = model(feature.unsqueeze(0))  #Add batch dimension\n","\n","# Run greedy decoder\n","decoded = greedy_decoder.forward(output.squeeze(0))  #Remove batch dimension if added earlier\n","print(decoded)"],"metadata":{"id":"aexZbz8J87sL","executionInfo":{"status":"aborted","timestamp":1744215899165,"user_tz":-60,"elapsed":16972,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Function to calculate Levenshtein Edit Distance\n","def lev_distance(pred_seq, label_seq):\n","\n","    # Initialize matrix of zeros\n","    m, n = len(pred_seq) + 1, len(label_seq) + 1\n","    dp = [[0] * n for _ in range(m)]\n","\n","    # Initialize first column and first row of the matrix\n","    for i in range(m):\n","        dp[i][0] = i\n","    for j in range(n):\n","        dp[0][j] = j\n","\n","    # Compute edit distance\n","    for i in range(1, m):\n","        for j in range(1, n):\n","            if pred_seq[i-1] == label_seq[j-1]:\n","                dp[i][j] = dp[i-1][j-1]  # No operation needed\n","            else:\n","                dp[i][j] = 1 + min(dp[i-1][j],    # Deletion\n","                                   dp[i][j-1],    # Insertion\n","                                   dp[i-1][j-1])  # Substitution\n","\n","    #Edit distance is the value in the bottom right corner of the matrix\n","    distance = dp[-1][-1]\n","    return distance\n","\n","#Test the function\n","assert lev_distance(['\\\\phi',\n","  'Right',\n","  '(',\n","  'Right',\n","  '0',\n","  'Right',\n","  '(',\n","  'Right',\n","  'n',\n","  'Right',\n","  ')',\n","  'Right',\n","  ')'],\n"," ['\\\\phi',\n","  'Right',\n","  '(',\n","  'Right',\n","  '\\\\phi',\n","  'Right',\n","  '(',\n","  'Right',\n","  'n',\n","  'Right',\n","  ')',\n","  'Right',\n","  ')']) == 1"],"metadata":{"id":"ByeUW6gaD53v","executionInfo":{"status":"ok","timestamp":1744215912549,"user_tz":-60,"elapsed":3,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import pytorch_lightning as pl\n","import torch\n","#from torchmetrics.functional.text.helper import _LevenshteinEditDistance as _LE_distance\n","\n","#Revised implementation of model with Word Error Rate added in\n","class MathClassificationModel(pl.LightningModule):\n","    def __init__(self, lr=0.001, input_size=4, output_size=109, hidden_size=128, num_layers = 3, decoder=None):\n","        super().__init__()\n","        self.model = LSTM_Model(input_size, hidden_size, num_layers, output_size)\n","        self.criterion = nn.CTCLoss(blank=output_size - 1)\n","        self.lr = lr\n","        self.decoder = decoder\n","        self.vocab=Vocab('/content/crohme_vocab.txt')\n","\n","\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y, x_lens, y_lens = batch\n","\n","        #Forward pass\n","        logits = self.model(x)\n","        log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n","\n","        #Calculate loss\n","        y_hat = self.model(x)\n","        y_hat = y_hat.permute(1, 0, 2)\n","        loss = self.criterion(y_hat.log_softmax(2), y, x_lens, y_lens)\n","\n","        #Calculate total edit distance\n","        total_edits = 0\n","        total_lens = 0\n","        for i in range(len(y)):\n","            with torch.no_grad():\n","                decoded = self.decoder(log_probs[i])\n","            pred_seq = decoded\n","            label_seq = [self.vocab.index2word[y[i][j].item()] for j in range(y_lens[i])]  # Convert indices to words\n","            lev_distances = lev_distance(pred_seq, label_seq)\n","\n","            #Calculate edit distance with every loop\n","            total_edits += lev_distances\n","            total_lens += y_lens[i]\n","\n","        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n","        self.log('train_wer', total_edits / total_lens, prog_bar=True, on_step=True, on_epoch=True)\n","        return loss\n","\n","\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y, x_lens, y_lens = batch\n","\n","        #Forward pass\n","        logits = self.model(x)\n","        log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n","\n","        #Calculate loss\n","        y_hat = self.model(x)\n","        y_hat = y_hat.permute(1, 0, 2)\n","        loss = self.criterion(y_hat.log_softmax(2), y, x_lens, y_lens)\n","\n","        #Calculate total edit distance\n","        total_edits = 0\n","        total_lens = 0\n","        for i in range(len(y)):\n","            with torch.no_grad():\n","                decoded = self.decoder(log_probs[i])\n","            pred_seq = decoded\n","            label_seq = [self.vocab.index2word[y[i][j].item()] for j in range(y_lens[i])]  #Convert indices to words\n","            lev_distances = lev_distance(pred_seq, label_seq)\n","\n","            #Calculate edit distance with every loop\n","            total_edits += lev_distances\n","            total_lens += y_lens[i]\n","\n","        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n","        self.log('val_wer', total_edits / total_lens, prog_bar=True, on_step=False, on_epoch=True)\n","        return loss\n","\n","\n","\n","    def test_step(self, batch, batch_idx):\n","        x, y, x_lens, y_lens = batch\n","\n","        #Forward pass\n","        logits = self.model(x)\n","        log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n","\n","        #Calculate loss\n","        y_hat = self.model(x)\n","        y_hat = y_hat.permute(1, 0, 2)\n","        loss = self.criterion(y_hat.log_softmax(2), y, x_lens, y_lens)\n","\n","        #Calculate total edit distance\n","        total_edits = 0\n","        total_lens = 0\n","        for i in range(len(y)):\n","            with torch.no_grad():\n","                decoded = self.decoder(log_probs[i])\n","            pred_seq = decoded\n","            label_seq = [self.vocab.index2word[y[i][j].item()] for j in range(y_lens[i])]  #Convert indices to words\n","            lev_distances = lev_distance(pred_seq, label_seq)\n","\n","            #Calculate edit distance with every loop\n","            total_edits += lev_distances\n","            total_lens += y_lens[i]\n","\n","        self.log('test_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n","        self.log('test_wer', total_edits / total_lens, prog_bar=True, on_step=False, on_epoch=True)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"],"metadata":{"id":"B-ari3b4Evdm","executionInfo":{"status":"ok","timestamp":1744215915115,"user_tz":-60,"elapsed":11,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from pytorch_lightning import Trainer\n","\n","#HERE\n","\n","#Train the model with word error rate being minimized\n","train = Trainer(\n","    callbacks = [\n","        LearningRateMonitor(logging_interval='step'),\n","        ModelCheckpoint(filename='{epoch}-{val_wer:.4f}', save_top_k=5, monitor='val_wer', mode='min'),\n","    ],\n","    logger = TensorBoardLogger('lightning_logs'),\n","    check_val_every_n_epoch=1,\n","    fast_dev_run=False,\n","    default_root_dir='checkpoint',\n","    deterministic=False,\n","    max_epochs=10,\n","    log_every_n_steps=50,\n","    devices = 1,\n",")\n","\n","# Initialize the model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MathClassificationModel.load_from_checkpoint('/content/drive/MyDrive/FYP/epoch=9-val_wer=0.1221.ckpt', decoder=GreedyDecoder(dataset.vocab)).to(device)\n","model = model.to(device)\n","\n","dm = CROHMEDM(root_directory='/content/drive/MyDrive/CROHME2019/crohme2019',\n","                       train_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_train.txt',\n","                       validation_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt',\n","                       test_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_test.txt',\n","                       vocab_file='crohme_vocab.txt',\n","                       batch_size=32,\n","                      num_workers=4\n","                     )\n","\n","train.fit(model, dm)\n"],"metadata":{"id":"yFhcGcqQFL7f","executionInfo":{"status":"aborted","timestamp":1744215899179,"user_tz":-60,"elapsed":16984,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TESTING ON VALIDATION SET\n","#Load the best val_wer model\n","\n","from pytorch_lightning import Trainer\n","\n","train = Trainer(\n","    devices = 1,\n",")\n","\n","# Load the model from a checkpoint\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MathClassificationModel.load_from_checkpoint(\n","    '/content/epoch=1-val_wer=0.1200.ckpt',\n","    decoder=GreedyDecoder(dataset.vocab)\n",")\n","model = model.to(device)\n","\n","# Initialize the data module\n","dm = CROHMEDM(root_directory='/content/drive/MyDrive/CROHME2019/crohme2019',\n","                       train_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_train.txt',\n","                       validation_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt',\n","                       test_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_test.txt',\n","                       vocab_file='crohme_vocab.txt',\n","                       batch_size=32,\n","                      num_workers=4\n","                     )\n","\n","# Test the model\n","train.test(model, datamodule=dm)"],"metadata":{"id":"XasF6aY8U_7B","colab":{"base_uri":"https://localhost:8080/","height":270,"referenced_widgets":["d93df7e2710b48cb966da464eb51aca2","c4417eb627ec40df95773a28734a5629","030886cce07e4c2eafa0ee9b68c8863d","ba2cb0dbe7564d8f8fa72b6fd2b9599e","805708960de24f5685e5d81bfdc5c29a","e0ff5b24f5014b279eb078a158d4c5a8","2494915b2815440db41b28e6c40f2809","c12e606d30354a259a57bce4857f87f2","9eab99b0991e4f1c8921b1c115b4139e","5d1d704dd9784ecdb84d6063d0afabc0","d1b3c66dd9ce43aea7e92580a94537de"]},"outputId":"0ceada24-d5fe-4965-815c-72cdb7970b7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]},{"output_type":"stream","name":"stdout","text":["Total samples loaded: 8900\n","Total samples loaded: 986\n","Total samples loaded: 1198\n","Datasets initialized successfully!\n","Train Dataset Size: 8900\n","Validation Dataset Size: 986\n","Test Dataset Size: 1198\n"]},{"output_type":"display_data","data":{"text/plain":["Testing: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93df7e2710b48cb966da464eb51aca2"}},"metadata":{}}]},{"cell_type":"code","source":["def classify_edits(pred_seq, label_seq, vocab):\n","    #Define symbols and relations based on their indices\n","    symbols_range = set(range(0, 101))  #Assuming symbols are in this range\n","    relations_range = set(range(101, 108))  #Assuming relations are in this range\n","\n","    #Convert sequences from tokens to indices\n","    pred_indices = [vocab.word2index[token] for token in pred_seq if token in vocab.word2index]\n","    label_indices = [vocab.word2index[token] for token in label_seq if token in vocab.word2index]\n","\n","    #Separate the sequences into symbols and relations based on indices\n","    pred_symbols, pred_relations = [], []\n","    label_symbols, label_relations = [], []\n","    for idx in pred_indices:\n","        if idx in symbols_range:\n","            pred_symbols.append(idx)\n","        elif idx in relations_range:\n","            pred_relations.append(idx)\n","\n","    for idx in label_indices:\n","        if idx in symbols_range:\n","            label_symbols.append(idx)\n","        elif idx in relations_range:\n","            label_relations.append(idx)\n","\n","    #Calculate edit distances using the provided lev_distance function\n","    symbol_edits = lev_distance([vocab.index2word[idx] for idx in pred_symbols],\n","                                 [vocab.index2word[idx] for idx in label_symbols])\n","    relation_edits = lev_distance([vocab.index2word[idx] for idx in pred_relations],\n","                                   [vocab.index2word[idx] for idx in label_relations])\n","\n","    return symbol_edits, relation_edits, len(label_symbols), len(label_relations)"],"metadata":{"id":"T0m_jr7shwAd","executionInfo":{"status":"aborted","timestamp":1744215899184,"user_tz":-60,"elapsed":16988,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import pytorch_lightning as pl\n","\n","class MathClassificationModel(pl.LightningModule):\n","    def __init__(self, lr=0.001, input_size=4, output_size=109, hidden_size=128, num_layers=3, decoder=None):\n","        super().__init__()\n","        self.model = LSTM_Model(input_size, hidden_size, num_layers, output_size)\n","        self.criterion = nn.CTCLoss(blank=output_size - 1)\n","        self.lr = lr\n","        self.decoder = decoder\n","        self.vocab = Vocab('/content/crohme_vocab.txt')\n","        # Initialize accumulators\n","        self.metrics_accumulator = {'train': {'wer_symbol': [], 'wer_relation': []},\n","                                    'val': {'wer_symbol': [], 'wer_relation': []},\n","                                    'test': {'wer_symbol': [], 'wer_relation': []}}\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def calculate_wer(self, batch, mode='train'):\n","        x, y, x_lens, y_lens = batch\n","        logits = self.model(x)\n","        log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n","        loss = self.criterion(log_probs.permute(1, 0, 2), y, x_lens, y_lens)\n","\n","        total_symbol_edits, total_relation_edits = 0, 0\n","        total_symbol_lens, total_relation_lens = 0, 0\n","\n","        for i in range(len(y)):\n","            with torch.no_grad():\n","                decoded = self.decoder(log_probs[i])\n","            pred_seq = decoded\n","            label_seq = [self.vocab.index2word[y[i][j].item()] for j in range(y_lens[i])]\n","            symbol_edits, relation_edits, symbol_lens, relation_lens = classify_edits(pred_seq, label_seq, self.vocab)\n","\n","            total_symbol_edits += symbol_edits\n","            total_relation_edits += relation_edits\n","            total_symbol_lens += symbol_lens\n","            total_relation_lens += relation_lens\n","\n","        # Update accumulators\n","        if total_symbol_lens > 0:\n","            self.metrics_accumulator[mode]['wer_symbol'].append(total_symbol_edits / total_symbol_lens)\n","        if total_relation_lens > 0:\n","            self.metrics_accumulator[mode]['wer_relation'].append(total_relation_edits / total_relation_lens)\n","        return loss\n","\n","    def training_step(self, batch, batch_idx):\n","        return self.calculate_wer(batch, mode='train')\n","\n","    def validation_step(self, batch, batch_idx):\n","        return self.calculate_wer(batch, mode='val')\n","\n","    def test_step(self, batch, batch_idx):\n","        return self.calculate_wer(batch, mode='test')\n","\n","    def on_validation_epoch_end(self):\n","        #Aggregate and log metrics for validation\n","        avg_wer_symbol = sum(self.metrics_accumulator['val']['wer_symbol']) / len(self.metrics_accumulator['val']['wer_symbol'])\n","        avg_wer_relation = sum(self.metrics_accumulator['val']['wer_relation']) / len(self.metrics_accumulator['val']['wer_relation'])\n","        self.log('val_wer_symbol', avg_wer_symbol, prog_bar=True)\n","        self.log('val_wer_relation', avg_wer_relation, prog_bar=True)\n","        # Clear accumulators after logging\n","        self.metrics_accumulator['val'] = {'wer_symbol': [], 'wer_relation': []}\n","\n","\n","    def on_test_epoch_end(self):\n","        #Similar implementation as on_validation_epoch_end for test metrics\n","        avg_wer_symbol = sum(self.metrics_accumulator['test']['wer_symbol']) / len(self.metrics_accumulator['test']['wer_symbol'])\n","        avg_wer_relation = sum(self.metrics_accumulator['test']['wer_relation']) / len(self.metrics_accumulator['test']['wer_relation'])\n","        self.log('test_wer_symbol', avg_wer_symbol, prog_bar=True)\n","        self.log('test_wer_relation', avg_wer_relation, prog_bar=True)\n","        #Clear accumulators after logging\n","        self.metrics_accumulator['test'] = {'wer_symbol': [], 'wer_relation': []}\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"],"metadata":{"id":"N1cpT-9lhxhk","executionInfo":{"status":"aborted","timestamp":1744215899185,"user_tz":-60,"elapsed":16989,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pytorch_lightning import Trainer\n","\n","train = Trainer(\n","    devices = 1,\n",")\n","\n","# Load the model from a checkpoint\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MathClassificationModel.load_from_checkpoint(\n","    '/content/drive/MyDrive/FYP/epoch=9-val_wer=0.1221.ckpt',\n","    decoder=GreedyDecoder(dataset.vocab)\n",")\n","model = model.to(device)\n","\n","# Initialize the data module\n","dm = CROHMEDM(root_directory='/content/drive/MyDrive/CROHME2019/crohme2019',\n","                       train_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_train.txt',\n","                       validation_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt',\n","                       test_annotation='/content/drive/MyDrive/CROHME2019/crohme2019_test.txt',\n","                       vocab_file='crohme_vocab.txt',\n","                       batch_size=32,\n","                      num_workers=4\n","                     )\n","\n","# Test the model\n","train.test(model, datamodule=dm)\n"],"metadata":{"id":"IKKgSOpBiKDG","executionInfo":{"status":"aborted","timestamp":1744215899188,"user_tz":-60,"elapsed":16992,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Logging outputs to file"],"metadata":{"id":"sAg74VcMec9g"}},{"cell_type":"code","source":["'''device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MathClassificationModel.load_from_checkpoint('/content/epoch=9-val_wer=0.1221.ckpt')\n","model = model.to(device)\n","model.eval()\n","\n","dataset = CROHME(annotation='/content/drive/MyDrive/CROHME2019/crohme2019_valid.txt', root_directory='/content/drive/MyDrive/CROHME2019/crohme2019', vocab=Vocab('crohme_vocab.txt'))\n","\n","#print(len(dataset))\n","with open(\"output_logs.txt\", \"w\") as f:\n","    for i in range(1):\n","            #Fetch the feature and label\n","            feature, label, input_len, label_len = dataset.__getitem__(i)\n","            feature = feature.to(device)  # Move feature to the same device as the model\n","\n","            #Get the filename for visualization\n","            filename = dataset.ink_paths[i]  # Full path\n","            filename_only = os.path.basename(filename)  # Extract just the file name\n","\n","            #Load and visualize the InkML file first\n","            ink = Inkml(filename)\n","            visualize_file(ink)\n","\n","            #Initialize decoder\n","            greedy_decoder = GreedyDecoder(vocab)\n","\n","            #Run model forward pass\n","            output = model(feature.unsqueeze(0))  # Add batch dimension\n","\n","            #Decode output\n","            decoded = greedy_decoder.forward(output.squeeze(0))  # Remove batch dimension\n","            decoded_str = \" \".join(decoded)  # Convert list to string format\n","\n","            #Print decoded output after visualization\n","            print(f\"Decoded output for {filename_only}: {decoded_str}\")\n","            f.write(f\"Decoded output for {filename_only}: {decoded_str}\")'''\n"],"metadata":{"id":"SHWhAdWzjLZW","executionInfo":{"status":"aborted","timestamp":1744215899195,"user_tz":-60,"elapsed":16998,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","#Function to process an individual InkML file and return visualization and decoded output\n","def recognize(filename, model_path='/content/drive/MyDrive/FYP/epoch=9-val_wer=0.1221.ckpt'):\n","\n","    #Initialize device\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    #Load the trained model\n","    model = MathClassificationModel.load_from_checkpoint(model_path)\n","    model = model.to(device)\n","    model.eval()\n","\n","    #Initialize vocabulary and decoder\n","    vocab = Vocab('crohme_vocab.txt')\n","    greedy_decoder = GreedyDecoder(vocab)\n","\n","    #Read and process the InkML file\n","    try:\n","        ink = Inkml(filename)\n","        traces = ink.getTraces()\n","        traces = [remove_duplicate(trace) for trace in traces]  #Ensure no duplicate points\n","    except Exception as e:\n","        print(f\"Error reading file: {e}\")\n","        return None\n","\n","    #Visualize strokes\n","    path = '/content/' + filename\n","    ink = Inkml(path)\n","    visualize_file(ink)\n","\n","    #Extract features\n","    feature = feature_extraction(traces)\n","    feature_tensor = torch.tensor(feature, dtype=torch.float).to(device)\n","\n","    #Perform model inference\n","    output = model(feature_tensor.unsqueeze(0))  #Add batch dimension\n","\n","    #Decode output\n","    decoded = greedy_decoder.forward(output.squeeze(0))\n","    decoded_expression = ' '.join([i for i in decoded])\n","\n","    print(f\"Decoded Expression: {decoded_expression}\")\n","    return"],"metadata":{"id":"zehs2CCHu0Dg","executionInfo":{"status":"aborted","timestamp":1744215899199,"user_tz":-60,"elapsed":17002,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Test individual file recognition\n","\n","recognize('form_001_E1.inkml')"],"metadata":{"id":"R-w-yHy9u9GJ","executionInfo":{"status":"aborted","timestamp":1744215899199,"user_tz":-60,"elapsed":17001,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torch\n","from tqdm import tqdm\n","\n","def evaluate_model(model, dataloader, vocab, device):\n","\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    decoder = GreedyDecoder(vocab)\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n","            features, labels, input_lengths, label_lengths = batch\n","\n","            features = features.to(device)\n","            outputs = model(features)\n","\n","            for i in range(outputs.shape[0]):\n","                decoded = decoder.forward(outputs[i])\n","                pred_str = decoded  # Already a list of tokens\n","\n","                label_str = [vocab.index2word[idx.item()] for idx in labels[i][:label_lengths[i]]]\n","\n","                all_preds.append(pred_str)\n","                all_labels.append(label_str)\n","\n","\n","    return all_labels, all_preds\n","\n","\n","def compute_metrics(true_sequences, pred_sequences):\n","    true_tokens = []\n","    pred_tokens = []\n","\n","    for t_seq, p_seq in zip(true_sequences, pred_sequences):\n","        min_len = min(len(t_seq), len(p_seq))\n","        for i in range(min_len):\n","            true_tokens.append(t_seq[i])\n","            pred_tokens.append(p_seq[i])\n","\n","    labels = sorted(set(true_tokens + pred_tokens))\n","\n","    print(\"\\nOverall Classification Report:\\n\")\n","    print(classification_report(true_tokens, pred_tokens, labels=labels, zero_division=0))\n","\n","    cm = confusion_matrix(true_tokens, pred_tokens, labels=labels)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","    fig, ax = plt.subplots(figsize=(15, 15))\n","    disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')\n","    plt.title(\"Confusion Matrix (All Symbols)\")\n","    plt.show()\n","\n","    # --- Confusion Matrix for Relation Symbols ---\n","    relation_symbols = ['Above', 'Below', 'Inside', 'Right', 'NoRel', 'Sub', 'Sup']\n","    rel_true = []\n","    rel_pred = []\n","\n","    for t, p in zip(true_tokens, pred_tokens):\n","        if t in relation_symbols:\n","            rel_true.append(t)\n","            rel_pred.append(p)\n","\n","    if rel_true:\n","        print(\"\\nRelation Symbols Classification Report:\\n\")\n","        print(classification_report(rel_true, rel_pred, labels=relation_symbols, zero_division=0))\n","\n","        cm_rel = confusion_matrix(rel_true, rel_pred, labels=relation_symbols)\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm_rel, xticklabels=relation_symbols, yticklabels=relation_symbols, annot=True, cmap=\"Oranges\", fmt='g')\n","        plt.xlabel('Predicted')\n","        plt.ylabel('True')\n","        plt.title('Confusion Matrix for Relation Symbols Only')\n","        plt.show()\n","    else:\n","        print(\"No relation symbols found in predictions or ground truth.\")\n","\n","# --- Run the evaluation ---\n","dm.setup(\"test\")\n","test_loader = dm.test_dataloader()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MathClassificationModel.load_from_checkpoint('/content/drive/MyDrive/FYP/epoch=9-val_wer=0.1221.ckpt')\n","model = model.to(device)\n","\n","true_labels, pred_labels = evaluate_model(model, test_loader, dm.vocab, device)\n","compute_metrics(true_labels, pred_labels)\n","\n"],"metadata":{"id":"bFvzKpTlEOOu","executionInfo":{"status":"aborted","timestamp":1744215899200,"user_tz":-60,"elapsed":17002,"user":{"displayName":"Rahul Matade","userId":"17173470292785503470"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"}},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1a5c7496a2984e93a17efd9c21717a31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42b24886ac104eae900cc5d76673375b","IPY_MODEL_bec22cc6bbd94b82b4e20a7aa8841198","IPY_MODEL_178e86da71364ff5a929b458ff726316"],"layout":"IPY_MODEL_7be63f10809c452d92d5f15b00eebca0"}},"42b24886ac104eae900cc5d76673375b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc07cb5618dc429f87787ce26012d516","placeholder":"​","style":"IPY_MODEL_1bbcb121928a4ea6890317d6340cbe72","value":"Sanity Checking DataLoader 0: 100%"}},"bec22cc6bbd94b82b4e20a7aa8841198":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc5027f857964b7bb9c57ef93efa05a7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3fe10fe70b046b59cc758c3b1c06ec6","value":2}},"178e86da71364ff5a929b458ff726316":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10978f41d238448e91c0fa9923e31634","placeholder":"​","style":"IPY_MODEL_099be7b0cff242a2aeb909ba6dcebace","value":" 2/2 [00:03&lt;00:00,  0.53it/s]"}},"7be63f10809c452d92d5f15b00eebca0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"dc07cb5618dc429f87787ce26012d516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bbcb121928a4ea6890317d6340cbe72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc5027f857964b7bb9c57ef93efa05a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3fe10fe70b046b59cc758c3b1c06ec6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10978f41d238448e91c0fa9923e31634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"099be7b0cff242a2aeb909ba6dcebace":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cff7f9cdb6f443f972a233c105b2644":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bce5f2f70bc4420a9bd7ee8580ae9903","IPY_MODEL_c8198c97fcde40f49aa5323b066a1110","IPY_MODEL_72469622f83245ffaab39dc9bbf3f610"],"layout":"IPY_MODEL_88d8832253544669974d249384cd1575"}},"bce5f2f70bc4420a9bd7ee8580ae9903":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ab32367ce6d4740935a633ced4d570c","placeholder":"​","style":"IPY_MODEL_0db9e2772a72456fbbc31a5ebb0d167d","value":"Epoch 0:   0%"}},"c8198c97fcde40f49aa5323b066a1110":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_feef21d37e5e4e15876093025dbd60e2","max":1113,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08045f89ec0f48dc82202bc3c4da6cc4","value":0}},"72469622f83245ffaab39dc9bbf3f610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_170bbd4542084dc3968204a0ff7e3eda","placeholder":"​","style":"IPY_MODEL_3aaf0a8980c943b0a4f10dc538c9d9c7","value":" 0/1113 [00:00&lt;?, ?it/s]"}},"88d8832253544669974d249384cd1575":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"7ab32367ce6d4740935a633ced4d570c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db9e2772a72456fbbc31a5ebb0d167d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feef21d37e5e4e15876093025dbd60e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08045f89ec0f48dc82202bc3c4da6cc4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"170bbd4542084dc3968204a0ff7e3eda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aaf0a8980c943b0a4f10dc538c9d9c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d93df7e2710b48cb966da464eb51aca2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4417eb627ec40df95773a28734a5629","IPY_MODEL_030886cce07e4c2eafa0ee9b68c8863d","IPY_MODEL_ba2cb0dbe7564d8f8fa72b6fd2b9599e"],"layout":"IPY_MODEL_805708960de24f5685e5d81bfdc5c29a"}},"c4417eb627ec40df95773a28734a5629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0ff5b24f5014b279eb078a158d4c5a8","placeholder":"​","style":"IPY_MODEL_2494915b2815440db41b28e6c40f2809","value":"Testing DataLoader 0:   3%"}},"030886cce07e4c2eafa0ee9b68c8863d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c12e606d30354a259a57bce4857f87f2","max":38,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9eab99b0991e4f1c8921b1c115b4139e","value":1}},"ba2cb0dbe7564d8f8fa72b6fd2b9599e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d1d704dd9784ecdb84d6063d0afabc0","placeholder":"​","style":"IPY_MODEL_d1b3c66dd9ce43aea7e92580a94537de","value":" 1/38 [00:10&lt;06:22,  0.10it/s]"}},"805708960de24f5685e5d81bfdc5c29a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e0ff5b24f5014b279eb078a158d4c5a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2494915b2815440db41b28e6c40f2809":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c12e606d30354a259a57bce4857f87f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eab99b0991e4f1c8921b1c115b4139e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d1d704dd9784ecdb84d6063d0afabc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1b3c66dd9ce43aea7e92580a94537de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}